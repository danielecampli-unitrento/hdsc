{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59aef9d9",
   "metadata": {},
   "source": [
    "# Hyperwave: knowledge base embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a3d63",
   "metadata": {},
   "source": [
    "Let's import all the libraries needed for our knowledge base embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84fb6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mari/Github/hyperwave/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import warnings\n",
    "import torchhd\n",
    "import torch\n",
    "\n",
    "from urllib3.exceptions import NotOpenSSLWarning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0830f90",
   "metadata": {},
   "source": [
    "Now, let's configure the runtime environment settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "286d5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O configuration\n",
    "input_folder = '../data/ncdf'\n",
    "output_folder = '../data/ncdf'\n",
    "\n",
    "# Runtime configuration\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "# np.set_printoptions(suppress=True, precision=8)\n",
    "# torch.set_printoptions(precision=8, sci_mode=False)\n",
    "\n",
    "# Ignore annoying urllib3 warnings\n",
    "warnings.filterwarnings(\"ignore\", category=NotOpenSSLWarning)\n",
    "\n",
    "# Load dataset\n",
    "dataset = xr.load_dataarray(os.path.join(input_folder, \"nrm.orx.dataset.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ffd7c1",
   "metadata": {},
   "source": [
    "Other than simulated signals, which are by themselves hypervectors of 20'880 dimensions, we need two kind of additional hypervectors: a random set to label central frequencies, and another one to label radii sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b78c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_radii = dataset.radius.size\n",
    "no_frequencies = dataset.frequency.size\n",
    "embedding_size = 1024\n",
    "random_embedding_size = 1024\n",
    "vsa_encoding = \"BSC\"\n",
    "\n",
    "def embed(data, in_features, out_features, embed_type=\"random\", vsa=\"BSC\"):\n",
    "    mapping = {\n",
    "        \"random\": torchhd.embeddings.Random,\n",
    "        \"level\": torchhd.embeddings.Level,\n",
    "        \"density\": torchhd.embeddings.Density\n",
    "    }\n",
    "    if embed_type not in mapping:\n",
    "        raise ValueError(f\"Unknown embedding type: {embed_type}\")\n",
    "    embedding = mapping[embed_type](in_features, out_features, vsa=vsa)\n",
    "    return embedding(data)\n",
    "\n",
    "frequency_embeddings = embed(\n",
    "    torch.randn(no_frequencies, random_embedding_size),\n",
    "    in_features=random_embedding_size,\n",
    "    out_features=embedding_size,\n",
    "    embed_type=\"density\",\n",
    "    vsa=vsa_encoding)\n",
    "\n",
    "radius_embeddings = embed(\n",
    "    torch.randn(no_radii, random_embedding_size),\n",
    "    in_features=random_embedding_size,\n",
    "    out_features=embedding_size,\n",
    "    embed_type=\"density\",\n",
    "    vsa=vsa_encoding)\n",
    "\n",
    "print(f\"Frequencies embeddings: {np.shape(frequency_embeddings)}\")\n",
    "print(f\"Radii embeddings: {np.shape(radius_embeddings)}\")\n",
    "print(frequency_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfca08dd",
   "metadata": {},
   "source": [
    "Now we should embed our simulated signals into a suitable encoding. Since we have used HRR for both central frequencies and radii labels, we will do the same for our signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885fa333",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_embeddings = torch.tensor(dataset.sel(radius=300).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d40944",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_embeddings = xr.apply_ufunc(\n",
    "    embed,\n",
    "    testset_embeddings,\n",
    "    # torch.tensor(dataset.values),\n",
    "    dataset.time.size,\n",
    "    embedding_size,\n",
    "    \"density\",\n",
    "    vsa_encoding,\n",
    "    vectorize=True,   # Allows element-wise mapping\n",
    ")\n",
    "print(f\"Signals embeddings: {np.shape(signal_embeddings)}\")\n",
    "print(signal_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e5ea92",
   "metadata": {},
   "source": [
    "Now that we have all the embeddings for our dataset, we can incrementally try some experiments. For example, let's create a knowledge base hypervector binding central frequency labels with the corresponding simulated signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11264a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the kbe (knowledge base embedding) for radius=10\n",
    "# Operations syntax:                   bind := * | bundle := +\n",
    "# kbe[radius=10] :=\n",
    "#   [frequency=1MHz] * [signal=(radius=10,frequency=1MHz)    +\n",
    "#   [frequency=1MHz] * [signal=(radius=10,frequency=2MHz)    +\n",
    "#   ...\n",
    "#   [frequency=10MHz] * [signal=(radius=10,frequency=9MHz)]  +\n",
    "#   [frequency=10MHz] * [signal=(radius=10,frequency=10MHz)]\n",
    "\n",
    "kbe = torchhd.hash_table(frequency_embeddings, signal_embeddings)\n",
    "\n",
    "# Let's assume we want to know what is the signal like at 4MHz\n",
    "query_embedding = torchhd.inverse(frequency_embeddings[3])\n",
    "result = torchhd.bind(kbe, query_embedding)\n",
    "# Now let's perform a memory cleanup: the result vector should be the\n",
    "# closest to our simulated signal at frequency=4MHz\n",
    "print(torchhd.cleanup(result, signal_embeddings))\n",
    "\n",
    "torchhd.utils.plot_similarity(result, signal_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c18f9",
   "metadata": {},
   "source": [
    "We can see that the result has most similarity with element in position 3, i.e. with the signal having central frequency equal to 4MHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98088b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_simulations = 1000\n",
    "correct_validations = 0\n",
    "embedding_size = 1024\n",
    "random_embedding_size = 1024\n",
    "vsa_encoding = \"BSC\"\n",
    "\n",
    "no_simulations = 10\n",
    "correct_validations = 0\n",
    "for i in np.arange(no_simulations):\n",
    "    frequency_embeddings = embed(\n",
    "        torch.randn(no_frequencies, random_embedding_size),\n",
    "        in_features=random_embedding_size,\n",
    "        out_features=embedding_size,\n",
    "        embed_type=\"density\",\n",
    "        vsa=vsa_encoding)\n",
    "    query_index = 0   # Our query will be random_keys_embeddings[0]\n",
    "    query_embedding = frequency_embeddings[query_index]\n",
    "    correct_result = signal_embeddings[query_index]\n",
    "    kbe = torchhd.hash_table(frequency_embeddings, signal_embeddings)\n",
    "    # Let's assume we want to know what is the signal like at 4MHz\n",
    "    query_embedding = torchhd.inverse(query_embedding)\n",
    "    result = torchhd.bind(kbe, query_embedding)\n",
    "    nearest_match = torchhd.cleanup(result, signal_embeddings)\n",
    "    # nearest_match = nearest_inner_prod(result, frequency_embeddings)\n",
    "    if (nearest_match == correct_result).all():\n",
    "        correct_validations += 1\n",
    "print(f\"Query matching accuracy: {correct_validations / no_simulations * 100}%\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04612bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_keys, no_values = 20, 20\n",
    "embedding_size = 1024\n",
    "random_embedding_size = 1024\n",
    "vsa_encoding = \"BSC\"\n",
    "\n",
    "random_keys_embeddings = embed(\n",
    "    torch.randn(no_keys, random_embedding_size),\n",
    "    in_features=random_embedding_size,\n",
    "    out_features=embedding_size,\n",
    "    embed_type=\"density\",\n",
    "    vsa=vsa_encoding\n",
    ")\n",
    "random_values_embeddings = embed(\n",
    "    torch.randn(no_values, random_embedding_size),\n",
    "    in_features=random_embedding_size,\n",
    "    out_features=embedding_size,\n",
    "    embed_type=\"density\",\n",
    "    vsa=vsa_encoding\n",
    ")\n",
    "kbe = torchhd.hash_table(random_keys_embeddings, random_values_embeddings)\n",
    "query_embedding = torchhd.inverse(random_keys_embeddings[0])\n",
    "result = torchhd.bind(kbe, query_embedding)\n",
    "torchhd.utils.plot_similarity(result, random_values_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d3936d",
   "metadata": {},
   "source": [
    "Let's create a small experiment where we embed a knowledge base using random components for both keys and values of our dictionary data structure. In this way, we can compare the baseline accuracy of a random model w.r.t. our signal density projection embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_simulations = 10\n",
    "correct_validations = 0\n",
    "no_keys, no_values = 10, 10\n",
    "embedding_size = 1024\n",
    "random_embedding_size = 1024\n",
    "vsa_encoding = \"BSC\"\n",
    "\n",
    "for i in np.arange(no_simulations):\n",
    "    random_keys_embeddings = embed(\n",
    "        torch.randn(no_keys, random_embedding_size),\n",
    "        in_features=random_embedding_size,\n",
    "        out_features=embedding_size,\n",
    "        embed_type=\"density\",\n",
    "        vsa=vsa_encoding\n",
    "    )\n",
    "    random_values_embeddings = embed(\n",
    "        torch.randn(no_values, random_embedding_size),\n",
    "        in_features=random_embedding_size,\n",
    "        out_features=embedding_size,\n",
    "        embed_type=\"density\",\n",
    "        vsa=vsa_encoding\n",
    "    )\n",
    "    query_index = 0   # Our query will be random_keys_embeddings[0]\n",
    "    query_embedding = random_keys_embeddings[query_index]\n",
    "    correct_result = random_values_embeddings[query_index]\n",
    "    kbe = torchhd.hash_table(random_keys_embeddings, random_values_embeddings)\n",
    "    query_embedding = torchhd.inverse(query_embedding)\n",
    "    result = torchhd.bind(kbe, query_embedding)\n",
    "    nearest_match = torchhd.cleanup(result, random_values_embeddings)\n",
    "    if (nearest_match == correct_result).all():\n",
    "        correct_validations += 1\n",
    "print(f\"Query matching accuracy: {correct_validations / no_simulations * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e041ee68",
   "metadata": {},
   "source": [
    "The baseline accuracy of value retrieval using as keys signals embeddings or random samples is very similar; basically, we just lose ~1% of accuracy when using signals embeddings, probably because the density encoding still leaves some residuals of time-dependent correlations between datapoints. Now let's try to embed the whole dataset into a single knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f88812",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_radii = dataset.radius.size\n",
    "no_frequencies = dataset.frequency.size\n",
    "embedding_size = 32768\n",
    "random_embedding_size = 1024\n",
    "vsa_encoding = \"BSC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9931d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_embeddings = embed(\n",
    "    torch.randn(no_frequencies, random_embedding_size),\n",
    "    in_features=random_embedding_size,\n",
    "    out_features=embedding_size,\n",
    "    embed_type=\"density\",\n",
    "    vsa=vsa_encoding)\n",
    "\n",
    "radius_embeddings = embed(\n",
    "    torch.randn(no_radii, random_embedding_size),\n",
    "    in_features=random_embedding_size,\n",
    "    out_features=embedding_size,\n",
    "    embed_type=\"density\",\n",
    "    vsa=vsa_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for f in dataset[\"frequency\"].values:\n",
    "    signal_embeddings_by_radius = xr.apply_ufunc(\n",
    "        embed,\n",
    "        torch.tensor(dataset.sel(frequency=f).values),\n",
    "        dataset.time.size,\n",
    "        embedding_size,\n",
    "        \"density\",\n",
    "        vsa_encoding,\n",
    "        vectorize=True)\n",
    "    kbe = torchhd.hash_table(radius_embeddings, signal_embeddings_by_radius)\n",
    "    x.append(kbe)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20597bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_embeddings = xr.apply_ufunc(\n",
    "    embed,\n",
    "    torch.tensor(dataset.values),\n",
    "    dataset.time.size,\n",
    "    embedding_size,\n",
    "    \"density\",\n",
    "    vsa_encoding,\n",
    "    vectorize=True,   # Allows element-wise mapping\n",
    ")\n",
    "print(f\"Signals embeddings: {np.shape(signal_embeddings)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyperwave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
